{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n",
      "/home/tingli/.conda/envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sbi.inference import SNPE\n",
    "from sklearn.model_selection import KFold\n",
    "from sbi import utils as utils\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, Column\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"/raid/users/heigerm/catalogues/sp_x_apogee_x_spspectra_rvtab.fits\"\n",
    "# sp data\n",
    "HDUlist = fits.open(filename)\n",
    "# DESI\n",
    "sp_tab = Table(HDUlist['SPTAB'].data)   \n",
    "# APOGEE\n",
    "apogee_tab = Table(HDUlist['APOGEEDR17'].data) \n",
    "# DESI SP Spectra\n",
    "spectra = Table(HDUlist['SPECTRA_SP'].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "targets = ['FE_H', 'MG_FE', 'C_FE', 'O_FE', 'CI_FE', 'AL_FE', 'SI_FE', 'K_FE', 'CA_FE', 'MN_FE', 'NI_FE', 'LOGG', 'TEFF']\n",
    "feh_target, mgfe_target, cfe_target, ofe_target, cife_target, alfe_target, sife_target, kfe_target, cafe_target, mnfe_target, nife_target, log_g, temperature = (np.array(apogee_tab[col]) for col in targets)\n",
    "targets_arr = [feh_target, kfe_target, cfe_target, cafe_target, nife_target, mnfe_target, ofe_target, cife_target, alfe_target]\n",
    "# check for Al error = 0 case\n",
    "alfe_target_err = np.array(apogee_tab['AL_FE_ERR'])\n",
    "abnormal_rows = np.unique([index for target in targets_arr for index, value in enumerate(target) if value > 10] + \n",
    "                          [index for index, value in enumerate(alfe_target_err) if value == 0])\n",
    "\n",
    "\n",
    "# Mask the abnormal rows across relevant datasets\n",
    "mask = ~np.isin(np.arange(len(apogee_tab)), abnormal_rows)\n",
    "apogee_tab_masked = apogee_tab[mask]\n",
    "spectra_masked = spectra[mask]\n",
    "sp_tab_masked = sp_tab[mask]\n",
    "\n",
    "# Reconstruct target arrays with masked data\n",
    "target_values_masked = {target: np.array(apogee_tab_masked[target]) for target in targets}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7336"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spectra_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine spectra from the three arms and normalize\n",
    "gb_combined_spectra = Table(names=['combined_flux', 'combined_wavelength'], dtype=['object', 'object'])\n",
    "\n",
    "for row in spectra_masked:\n",
    "    # Combine and sort flux and wavelength from all arms\n",
    "    combined_flux = np.concatenate([row['flx_B'], row['flx_R'], row['flx_Z']])\n",
    "    combined_wavelength = np.concatenate([row['B_WAVELENGTH'], row['R_WAVELENGTH'], row['Z_WAVELENGTH']])\n",
    "    sort_order = np.argsort(combined_wavelength)\n",
    "    combined_flux, combined_wavelength = combined_flux[sort_order], combined_wavelength[sort_order]\n",
    "\n",
    "    # Normalize flux\n",
    "    global_median = np.median(combined_flux)\n",
    "    IQR = np.percentile(combined_flux, 75) - np.percentile(combined_flux, 25)\n",
    "    normalized_flux = (combined_flux - global_median) / IQR\n",
    "\n",
    "    gb_combined_spectra.add_row([normalized_flux, combined_wavelength])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux = np.array(gb_combined_spectra['combined_flux'])\n",
    "# Input spectra\n",
    "X = np.array([np.array(flux_val, dtype=float) for flux_val in flux])\n",
    "# Parameters\n",
    "theta = np.column_stack([target_values_masked[target] for target in targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of X: 7336\n",
      "Dimensions of X: 13787\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of X:\", len(X))\n",
    "print(\"Dimensions of X:\", len(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store results\n",
    "results = {target: {'var': [], 'pred': [], 'res': [], 'exp': []} for target in targets}\n",
    "\n",
    "# Iterate through the folds\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X, theta)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = theta[train_index], theta[test_index]\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train, X_test = scaler.transform(X_train), scaler.transform(X_test)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train, X_test, y_train, y_test = map(torch.Tensor, (X_train, X_test, y_train, y_test))\n",
    "\n",
    "\n",
    "    # load the posterior model saved\n",
    "    model_pkl_file = f\"SBI_fold_{fold}.pkl\" \n",
    "    \n",
    "    with open(model_pkl_file, 'rb') as file:\n",
    "        posterior = pickle.load(file)\n",
    "        \n",
    "    # store the metallicity and abundance results \n",
    "    # original code:\n",
    "    n_samples = 250\n",
    "\n",
    "    for idx in range(len(X_test)):\n",
    "        samples = posterior.sample((n_samples,), x=X_test[idx])\n",
    "        \n",
    "        # Iterate over each target and store the results\n",
    "        for i, target in enumerate(targets):\n",
    "            target_samples = samples[:, i]\n",
    "            target_exp = y_test[idx][i]\n",
    "            target_pred = torch.mean(target_samples)\n",
    "            target_res = target_pred - target_exp\n",
    "            target_var = torch.var(target_samples)\n",
    "            \n",
    "            results[target]['exp'].append(target_exp)\n",
    "            results[target]['pred'].append(target_pred)\n",
    "            results[target]['res'].append(target_res)\n",
    "            results[target]['var'].append(target_var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After collecting all the results in the results dictionary\n",
    "for target in results:\n",
    "    results[target]['exp'] = torch.stack(results[target]['exp'])\n",
    "    results[target]['pred'] = torch.stack(results[target]['pred'])\n",
    "    results[target]['res'] = torch.stack(results[target]['res'])\n",
    "    results[target]['var'] = torch.stack(results[target]['var'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Table of Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store the summary statistics\n",
    "summary_df = pd.DataFrame(columns=[\"Target\", \"Mean\", \"Median\", \"IQR\", \"Variance\"])\n",
    "\n",
    "# Calculate the statistics for each target and add them to the DataFrame\n",
    "for target in results:\n",
    "    residuals = results[target]['res'].numpy()\n",
    "    mean_res = np.mean(residuals)\n",
    "    median_res = np.median(residuals)\n",
    "    iqr_res = np.percentile(residuals, 75) - np.percentile(residuals, 25)\n",
    "    var_res = np.var(residuals)\n",
    "    \n",
    "    # Append a new row to the DataFrame\n",
    "    summary_df = summary_df.append({\n",
    "        \"Target\": target,\n",
    "        \"Mean\": mean_res,\n",
    "        \"Median\": median_res,\n",
    "        \"IQR\": iqr_res,\n",
    "        \"Variance\": var_res\n",
    "    }, ignore_index=True)\n",
    "\n",
    "# Set the 'Target' column as the index\n",
    "summary_df.set_index('Target', inplace=True)\n",
    "\n",
    "# Print the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metallicity Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))  \n",
    "\n",
    "plt.scatter(results['FE_H']['exp'].numpy(), results['FE_H']['pred'].numpy(), alpha=0.5, color='b', edgecolors='k', marker='o')\n",
    "plt.xlim(-2, 0.5)\n",
    "plt.ylim(-2, 0.5)\n",
    "plt.xlabel(\"[Fe/H] Expected Values\", fontsize=14)\n",
    "plt.ylabel(\"Predicted Values\", fontsize=14)\n",
    "plt.title(\"Predicted vs. Expected [Fe/H]\", fontsize=16)\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bins and colormap\n",
    "xbin = np.linspace(-2, 0.5, 100)\n",
    "ybin = np.linspace(-0.75, 0.75, 50)\n",
    "cmap = plt.cm.viridis\n",
    "\n",
    "# Extract the expected and residual values for FE_H from the results dictionary\n",
    "feh_exp = results['FE_H']['exp'].numpy()\n",
    "feh_res = results['FE_H']['res'].numpy()\n",
    "\n",
    "# Calculate the statistics for the residuals across bins\n",
    "def calculate_stats(bin_edges, values):\n",
    "    centers = []\n",
    "    lower, median, upper = [], [], []\n",
    "    for n in range(len(bin_edges) - 1):\n",
    "        in_bin = (values >= bin_edges[n]) & (values < bin_edges[n + 1])\n",
    "        if in_bin.any():\n",
    "            center = (bin_edges[n + 1] + bin_edges[n]) / 2\n",
    "            centers.append(center)\n",
    "            percentiles = np.percentile(values[in_bin], [16, 50, 84])\n",
    "            lower.append(percentiles[0])\n",
    "            median.append(percentiles[1])\n",
    "            upper.append(percentiles[2])\n",
    "    return centers, lower, median, upper\n",
    "\n",
    "# Calculate stats for the expected FE_H values\n",
    "centers, lower, median, upper = calculate_stats(xbin, feh_exp)\n",
    "l = np.interp(xbin, centers, lower)\n",
    "m = np.interp(xbin, centers, median)\n",
    "u = np.interp(xbin, centers, upper)\n",
    "\n",
    "# Get the DESI and APOGEE [Fe/H] values from the masked tables\n",
    "desi_feh = np.array(sp_tab_masked['Fe_H_sp'])\n",
    "apogee_feh = np.array(apogee_tab_masked['FE_H'])\n",
    "r1 = desi_feh - apogee_feh\n",
    "\n",
    "# Calculate stats for the APOGEE FE_H values\n",
    "centers1, lower1, median1, upper1 = calculate_stats(xbin, apogee_feh)\n",
    "l1 = np.interp(xbin, centers1, lower1)\n",
    "m1 = np.interp(xbin, centers1, median1)\n",
    "u1 = np.interp(xbin, centers1, upper1)\n",
    "\n",
    "# Plot the 2D histograms\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 12))\n",
    "\n",
    "# Plot for DESI - APOGEE [Fe/H]\n",
    "ax1.hist2d(apogee_feh, r1, bins=(xbin, ybin), cmap=cmap)\n",
    "ax1.plot(xbin, l1, 'k--', label='-1$\\sigma$', lw=2)\n",
    "ax1.plot(xbin, m1, 'k', label='Median', lw=2)\n",
    "ax1.plot(xbin, u1, 'k:', label='+1$\\sigma$', lw=2)\n",
    "ax1.set_ylabel('$\\Delta$ Before', fontsize=18)\n",
    "ax1.legend(fontsize=16)\n",
    "ax1.tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "# Plot for Predicted - Expected [Fe/H]\n",
    "ax2.hist2d(feh_exp, feh_res, bins=(xbin, ybin), cmap=cmap)\n",
    "ax2.plot(xbin, l, 'k--', label='-1$\\sigma$', lw=2)\n",
    "ax2.plot(xbin, m, 'k', label='Median', lw=2)\n",
    "ax2.plot(xbin, u, 'k:', label='+1$\\sigma$', lw=2)\n",
    "ax2.set_xlabel('APOGEE [Fe/H]', fontsize=18)\n",
    "ax2.set_ylabel('$\\Delta$ After', fontsize=18)\n",
    "ax2.legend(fontsize=18)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.05)\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = fig.colorbar(ax1.images[0], ax=[ax1, ax2], orientation='vertical')\n",
    "cbar.ax.tick_params(labelsize=16) \n",
    "cbar.set_label('# of stars', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e3c0d2cb689c9f3ddfdcc20370a54f5a0d1f4658107fa1312f8e0c21d7f27d67"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
